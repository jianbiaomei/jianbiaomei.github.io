@article{mei2024dreamforge,
  title={DreamForge: Motion-Aware Autoregressive Video Generation for Multi-View Driving Scenes},
  author={Mei, Jianbiao and Yang, Xuemeng and Wen, Licheng and Hu Tao and Yu Yang and Wei, Tiantian and Ma, Yukai and Dou, Min and Shi, Botian and Liu, Yong},
  journal={arXiv preprint arXiv:2409.04003},
  year={2024},
  arxiv       = {2409.04003},
  bibtex_show = {true},
  abbr        = {Preprint},
  demo        = {https://pjlab-adg.github.io/DriveArena/dreamforge},
  selected    = {true}
}

@inproceedings{mei2024continuously,
  title={Continuously Learning, Adapting, and Improving: A Dual-Process Approach to Autonomous Driving},
  author={Mei*, Jianbiao and Ma*, Yukai and Yang, Xuemeng and Wen, Licheng and Cai, Xinyu and Li, Xin and Fu, Daocheng and Zhang, Bo and Cai, Pinlong and Dou, Min and others},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2024},
  abbr        = {NeurIPS},
  arxiv       = {2405.15324},
  bibtex_show = {true},
  code        = {https://github.com/pjlab-adg/leapad},
  demo        = {https://leapad-2024.github.io/LeapAD/},
  selected    = {true}
}

@article{mei2024camera,
  title={Camera-based 3d semantic scene completion with sparse guidance network},
  author={Mei, Jianbiao and Yang, Yu and Wang, Mengmeng and Zhu, Junyu and Ra, Jongwon and Ma, Yukai and Li, Laijian and Liu, Yong},
  journal={IEEE Transactions on Image Processing (TIP)},
  year={2024},
  publisher={IEEE},
  bibtex_show = {true},
  abbr        = {TIP},
  arxiv       = {2312.05752},
  code        = {https://github.com/Jieqianyu/SGN},
  selected    = {true}    
}

@article{mei2024learning,
  title={Learning spatiotemporal relationships with a unified framework for video object segmentation},
  author={Mei, Jianbiao and Wang, Mengmeng and Yang, Yu and Li, Zizhang and Liu, Yong},
  journal={Applied Intelligence (APIN)},
  pages={1--16},
  year={2024},
  publisher={Springer},
  bibtex_show = {true},
  abbr        = {APIN},
  pdf       = {https://link.springer.com/article/10.1007/s10489-024-05486-y},
  selected    = {true}
}

@article{mei2024lidar,
  title={LiDAR video object segmentation with dynamic kernel refinement},
  author={Mei, Jianbiao and Yang, Yu and Wang, Mengmeng and Li, Zizhang and Ra, Jongwon and Liu, Yong},
  journal={Pattern Recognition Letters (PRL)},
  volume={178},
  pages={21--27},
  year={2024},
  publisher={North-Holland},
  bibtex_show = {true},
  abbr        = {PRL},
  pdf       = {https://www.sciencedirect.com/science/article/abs/pii/S0167865523003604},
  selected    = {true}
}

@inproceedings{mei2023centerlps,
  title={Centerlps: Segment instances by centers for lidar panoptic segmentation},
  author={Mei*, Jianbiao and Yang*, Yu and Wang, Mengmeng and Li, Zizhang and Hou, Xiaojun and Ra, Jongwon and Li, Laijian and Liu, Yong},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia (ACM MM)},
  pages={1884--1894},
  year={2023},
  bibtex_show = {true},
  abbr        = {ACM MM},
  pdf       = {https://dl.acm.org/doi/10.1145/3581783.3612080},
  selected    = {true}
}

@inproceedings{mei2023panet,
  title={PANet: LiDAR Panoptic Segmentation with Sparse Instance Proposal and Aggregation},
  author={Mei, Jianbiao and Yang, Yu and Wang, Mengmeng and Hou, Xiaojun and Li, Laijian and Liu, Yong},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={7726--7733},
  year={2023},
  organization={IEEE},
  bibtex_show = {true},
  abbr        = {IROS},
  arxiv       = {2306.15348},
  code        = {https://github.com/Jieqianyu/PANet},
  selected    = {true}
}

@inproceedings{mei2023ssc,
  title={SSC-RS: Elevate LiDAR semantic scene completion with representation separation and BEV fusion},
  author={Mei, Jianbiao and Yang, Yu and Wang, Mengmeng and Huang, Tianxin and Yang, Xuemeng and Liu, Yong},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1--8},
  year={2023},
  organization={IEEE},
  bibtex_show = {true},
  abbr        = {IROS},
  arxiv       = {2306.15349},
  code        = {https://github.com/Jieqianyu/SSC-RS},
  selected    = {true}
}

@article{mei2023fast,
  title={Fast real-time video object segmentation with a tangled memory network},
  author={Mei*, Jianbiao and Wang*, Mengmeng and Yang, Yu and Li, Yanjun and Liu, Yong},
  journal={ACM Transactions on Intelligent Systems and Technology (ACM TIST)},
  volume={14},
  number={3},
  pages={1--21},
  year={2023},
  publisher={ACM New York, NY},
  bibtex_show = {true},
  abbr        = {ACM TIST},
  pdf       = {https://dl.acm.org/doi/abs/10.1145/3585076},
  selected    = {true}
}

@article{wang2022delving,
  title={Delving deeper into mask utilization in video object segmentation},
  author={Wang*, Mengmeng and Mei*, Jianbiao and Liu, Lina and Tian, Guanzhong and Liu, Yong and Pan, Zaisheng},
  journal={IEEE Transactions on Image Processing (TIP)},
  volume={31},
  pages={6255--6266},
  year={2022},
  publisher={IEEE},
  bibtex_show = {true},
  abbr        = {TIP},
  pdf       = {https://ieeexplore.ieee.org/document/9904497},
  selected    = {true}
}

@article{mei2021transvos,
  title={Transvos: Video object segmentation with transformers},
  author={Mei*, Jianbiao and Wang*, Mengmeng and Lin, Yeneng and Yuan, Yi and Liu, Yong},
  journal={arXiv preprint arXiv:2106.00588},
  year={2021},
  arxiv       = {2106.00588},
  bibtex_show = {true},
  abbr        = {Preprint},
  code        = {https://github.com/sallymmx/TransVOS},
  selected    = {true}
}



@article{yang2024driving,
  title={Driving in the Occupancy World: Vision-Centric 4D Occupancy Forecasting and Planning via World Models for Autonomous Driving},
  author={Yang*, Yu and Mei*, Jianbiao and Ma, Yukai and Du, Siliang and Chen, Wenqing and Qian, Yijie and Feng, Yuxiang and Liu, Yong},
  journal={arXiv preprint arXiv:2408.14197},
  year={2024},
  arxiv       = {2408.14197},
  bibtex_show = {true},
  abbr        = {Preprint},
  selected    = {true}
}

@article{yang2024dqformer,
  title={DQFormer: Towards Unified LiDAR Panoptic Segmentation with Decoupled Queries},
  author={Yang*, Yu and Mei*, Jianbiao and Liu, Liang and Du, Siliang and Xiao, Yilin and Ra, Jongwon and Liu, Yong and Xu, Xiao and Wu, Huifeng},
  journal={arXiv preprint arXiv:2408.15813},
  year={2024},
  arxiv       = {2408.15813},
  bibtex_show = {true},
  abbr        = {Preprint},
}

@article{yang2024drivearena,
  title={Drivearena: A closed-loop generative simulation platform for autonomous driving},
  author={Yang*, Xuemeng and Wen*, Licheng and Ma*, Yukai and Mei*, Jianbiao and Li*, Xin and Wei*, Tiantian and Lei, Wenjie and Fu, Daocheng and Cai, Pinlong and Dou, Min and others},
  journal={arXiv preprint arXiv:2408.00415},
  year={2024},
  arxiv       = {2408.00415},
  bibtex_show = {true},
  abbr        = {Preprint},
  code        = {https://github.com/pjlab-adg/DriveArena},
  demo        = {https://pjlab-adg.github.io/DriveArena/}
}

@article{ma2024licrocc,
  title={LiCROcc: Teach Radar for Accurate Semantic Occupancy Prediction using LiDAR and Camera},
  author={Ma*, Yukai and Mei*, Jianbiao and Yang, Xuemeng and Wen, Licheng and Xu, Weihua and Zhang, Jiangning and Shi, Botian and Liu, Yong and Zuo, Xingxing},
  journal={arXiv preprint arXiv:2407.16197},
  year={2024},
  arxiv       = {2407.16197},
  bibtex_show = {true},
  abbr        = {Preprint},
  demo        = {https://hr-zju.github.io/LiCROcc}
}



@inproceedings{li2022nerv,
  title={E-nerv: Expedite neural video representation with disentangled spatial-temporal context},
  author={Li, Zizhang and Wang, Mengmeng and Pi, Huaijin and Xu, Kechun and Mei, Jianbiao and Liu, Yong},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={267--284},
  year={2022},
  organization={Springer Nature Switzerland Cham},
  arxiv       = {2207.08132},
  bibtex_show = {true},
  abbr        = {ECCV},
  code        = {https://github.com/kyleleey/E-NeRV}
}

@article{yang2023exploiting,
  title={Exploiting semantic-level affinities with a mask-guided network for temporal action proposal in videos},
  author={Yang, Yu and Wang, Mengmeng and Mei, Jianbiao and Liu, Yong},
  journal={Applied Intelligence (APIN)},
  volume={53},
  number={12},
  pages={15516--15536},
  year={2023},
  publisher={Springer US New York},
  bibtex_show = {true},
  abbr        = {APIN},
  pdf       = {https://link.springer.com/article/10.1007/s10489-022-04261-1}
}

@article{li2023geo,
  title={Geo-localization with transformer-based 2D-3D match network},
  author={Li, Laijian and Ma, Yukai and Tang, Kai and Zhao, Xiangrui and Chen, Chao and Huang, Jianxin and Mei, Jianbiao and Liu, Yong},
  journal={IEEE Robotics and Automation Letters (RAL)},
  year={2023},
  publisher={IEEE},
  bibtex_show = {true},
  abbr        = {RAL},
  pdf       = {https://ieeexplore.ieee.org/document/10168166},
  code        = {https://github.com/yzdad/D-GLSNet}
}

@inproceedings{wang2024multimodal,
  title={A Multimodal, Multi-Task Adapting Framework for Video Action Recognition},
  author={Wang, Mengmeng and Xing, Jiazheng and Jiang, Boyuan and Chen, Jun and Mei, Jianbiao and Zuo, Xingxing and Dai, Guang and Wang, Jingdong and Liu, Yong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  volume={38},
  number={6},
  pages={5517--5525},
  year={2024},
  bibtex_show = {true},
  abbr        = {AAAI},
  arxiv       = {2401.11649}
}

@inproceedings{fu2024coarse,
  title={A Coarse-to-Fine Place Recognition Approach using Attention-guided Descriptors and Overlap Estimation},
  author={Fu, Chencan and Li, Lin and Mei, Jianbiao and Ma, Yukai and Peng, Linpeng and Zhao, Xiangrui and Liu, Yong},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={8493--8499},
  year={2024},
  organization={IEEE},
  bibtex_show = {true},
  abbr        = {ICRA},
  arxiv       = {2303.06881}
}

@article{wang2023actionclip,
  title={Actionclip: Adapting language-image pretrained models for video action recognition},
  author={Wang, Mengmeng and Xing, Jiazheng and Mei, Jianbiao and Liu, Yong and Jiang, Yunliang},
  journal={IEEE Transactions on Neural Networks and Learning Systems (TNNLS)},
  year={2023},
  publisher={IEEE},
  bibtex_show = {true},
  abbr        = {TNNLS},
  pdf       = {https://ieeexplore.ieee.org/document/10323592}
}

@inproceedings{ra2024exploit,
  title={Exploit Spatiotemporal Contextual Information for 3D Single Object Tracking via Memory Networks},
  author={Ra, Jongwon and Wang, MengMeng and Mei, Jianbiao and Liu, Shanqi and Yang, Yu and Liu, Yong},
  booktitle={2024 International Conference on 3D Vision (3DV)},
  pages={842--851},
  year={2024},
  organization={IEEE},
  bibtex_show = {true},
  abbr        = {3DV},
  pdf       = {https://ieeexplore.ieee.org/document/10550656}
}

@article{li2021mail,
  title={Mail: A unified mask-image-language trimodal network for referring image segmentation},
  author={Li, Zizhang and Wang, Mengmeng and Mei, Jianbiao and Liu, Yong},
  journal={arXiv preprint arXiv:2111.10747},
  year={2021},
  arxiv       = {2111.10747},
  bibtex_show = {true},
  abbr        = {Preprint},
}

@article{xiang2023cr,
  title={CR-SFP: Learning Consistent Representation for Soft Filter Pruning},
  author={Xiang, Jingyang and Chen, Zhuangzhi and Mei, Jianbiao and Li, Siqi and Chen, Jun and Liu, Yong},
  journal={arXiv preprint arXiv:2312.11555},
  year={2023},
  arxiv       = {2312.11555},
  bibtex_show = {true},
  abbr        = {Preprint},
}
